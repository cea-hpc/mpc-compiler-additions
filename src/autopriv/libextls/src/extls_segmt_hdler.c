#define _GNU_SOURCE
#include <config.h>
#include <link.h>
#include "extls_segmt_hdler.h"
#include "extls_list.h"

#define TLS_SEGS_NB_MAX 16                                     /**< base number of loaded shared objects */

static extls_size_t* offset_table = NULL;                      /**< table containing each segment offset in static segment */
static extls_lock_t offset_table_lock = EXTLS_LOCK_INITIALIZER;/**< lock to manipulate the global table */
static int offset_table_fd = -1;                               /**< unique fd for "copy-on-write"'ing the static semgent */
static extls_size_t offset_table_memsz = 0;                    /**< total size of static segment */
static elem_t* static_order = NULL;

static size_t tls_segs_nb = 0;                                 /**< number of shared object containing a TLS segment */
static extls_tls_seg_t* tls_segs_tab = NULL;                   /**< array containing TLS segment description */
static extls_rwlock_t tls_tab_lock = EXTLS_RWLOCK_INITIALIZER; /**< lock to manipulate the array */

/**
 * \brief print a specific segment w/ a fancy format :)
 *
 * It would probably be better if only one argument was passed: the segment index. From
 * that it is possible to infer the segment pointer and the module id.
 *
 * \param seg the segment to print
 * \param module_id the module id whose the segment refers to
 * \return EXTLS_SUCCESS whatever the state
 */
static inline extls_ret_t extls_print_tls_segment(extls_tls_seg_t* seg, extls_size_t module_id)
{
	char* addr = (char*)seg->seg_addr;
	size_t sz   = (size_t)seg->seg_memsz;
	const char * name = (strcmp(seg->obj_name, "")!=0) ? seg->obj_name : "The executable itself";
	extls_dbg("M_ID=%lu %%%lu ["GRE"%14p"BLU" - "RED"%14p"BLU"] --> "YEL"%s", module_id, seg->seg_align, addr, addr+sz, name);

	return EXTLS_SUCCESS;
}

/**
 * \brief Dump the complete TLS segment table w/ a fancy format.
 *
 * It simply call extls_print_tls_segment for each segment (obviously)
 * \see extls_print_tls_segment
 * \return EXTLS_SUCCESS whatever the state
 */
extls_ret_t extls_print_tls_segments(void)
{
	extls_size_t i;

	extls_dbg("=========> TLS SEGMENT MAPPINGS LIST <=========");
	for(i=0; i<tls_segs_nb; i++)
	{
		(void)extls_print_tls_segment(&(tls_segs_tab[i]), i+1);
	}
	extls_dbg("===============================================");
	return EXTLS_SUCCESS;
}

/**
 * \brief Stores TLS segments in global table (through dl_iterate_pheader call)
 *
 * This function works because of one important thing: the loader pass through
 * each program header and, for each shared object to load, it calls "_dl_next_moduleid()"
 * incrementing by 1 each time a PT_TLS segment is discovered (and registered)
 * To find the TLS segment associated to a given module without modifying the loader, we
 * just have to follow the same semantic. As "dl_iterate_phdr()" is called for each successive
 * program header, we can guarantee that the module id will remain consistent.
 *
 * \param info struct generated by the loader which contains current program header infos
 * \param sz not used by our library => sizeof dl_phdr_info
 * \param data contains NULL when static TLS are parsed, and contains a dyn_data_s when dlopen'd TLS are loaded.
 *
 * \return EXTLS_SUCCESS whatever the final state
 *
 */
static int extls_lookfor_tls_segment(struct dl_phdr_info* info, size_t sz, void* data)
{
	int i, nb_segs = info->dlpi_phnum;
	const char* filename = "none";
	void * handler = NULL;

	/* describes info struct's size */
	UNUSED(sz);

	/* we the function is called to parse dynamically loaded objects,
	 * data will contains the file name and the handler (from dlopen())
	 * This will help to make the difference between static and dynamic loads
	 */
	if(data != NULL)
	{
		filename = ((dyn_data_t*)data)->name;
		handler = ((dyn_data_t*)data)->handler;
	}

	//TLS segments are generally the N-th or (N-1)-th ELF segment
	for(i = nb_segs - 1 ; i >= 0; i--)
	{
		Elf_Phdr seg = info->dlpi_phdr[i];
		
		//if not a TLS segment, don't care !
		if(seg.p_type != PT_TLS) continue;

		/* check if the segment is already registered */
		short found = 0;
		size_t cpt = 0;
		while(!found && cpt < tls_segs_nb)
		{
			found = (strcmp(info->dlpi_name, tls_segs_tab[cpt].obj_name) == 0);
			cpt++;
		}

		extls_dbg("Segment Lookup: Discovering %s", (strcmp(info->dlpi_name, "")!=0) ? info->dlpi_name : "the executable segment");

		if(found){
			/* if already added, just update the handler */
			if(strcmp(info->dlpi_name, filename) == 0)
			{
				tls_segs_tab[cpt-1].dyn_handler = handler;
			}
			/* no need to insert the segment */
			break;
		}

		/* check if our table need a reallocation (by default, we can handle TLS_SEGS_NB_MAX without reallocation) 
		 * In this case, if tls_segs_nb % TLS_SEGS_NB_MAX == 0,
		 * it means that we have to allocate one more TLS array
		 */
		if((tls_segs_nb % TLS_SEGS_NB_MAX) == 0 && tls_segs_nb != 0)
		{
			/* how many TLS arrays already filled */
			size_t nb_blocks = (int)(tls_segs_nb/TLS_SEGS_NB_MAX);
			/* allocate one more */
			tls_segs_tab = realloc(tls_segs_tab, sizeof(extls_tls_seg_t)*(nb_blocks + 1));
			if(!tls_segs_tab) return EXTLS_ENOMEM;
		}

		/* add a new entry */
		tls_segs_tab[tls_segs_nb].obj_name  = info->dlpi_name;
		tls_segs_tab[tls_segs_nb].seg_addr  = (void*)info->dlpi_addr + (unsigned long)seg.p_vaddr;
		tls_segs_tab[tls_segs_nb].seg_filesz = seg.p_filesz;
		tls_segs_tab[tls_segs_nb].seg_memsz = seg.p_memsz;
		tls_segs_tab[tls_segs_nb].seg_align = seg.p_align;

		/* if the newly discovered TLS segment is dynamically loaded, register the dlopen() handler */
		if(strcmp(info->dlpi_name, filename) == 0)
		{
			tls_segs_tab[tls_segs_nb].dyn_handler = handler;
		}

		tls_segs_nb++;

		/* It must (or should?) be only one PT_TLS block per object */
		break;
	}

	return EXTLS_SUCCESS;
}

/**
 * \brief from the dlopen() handler, tries to locate the associated TLS segment, if any
 * \param idx A pointer which will be filled with the effective module index
 * \param handler a previously called dlopen()'s pointer
 * \return
 * <ul>
 * <li><b>EXTLS_ENFOUND</b> if unable to locate the handler in any of registered segments</li>
 * <li><b>EXTLS_SUCCESS</b> otherwise</li>
 * </ul>
 */
extls_ret_t extls_get_dyn_tls_segmt_index(extls_size_t *idx, void* handler)
{
	extls_size_t i;
	extls_ret_t ret = EXTLS_ENFOUND;
	extls_rlock(&tls_tab_lock);
	for(i=0; i<tls_segs_nb; i++)
	{
		if(tls_segs_tab[i].dyn_handler == handler)
		{
			*idx = i;
			ret = EXTLS_SUCCESS;
			goto ret_func;
		}
	}

ret_func:
	extls_runlock(&tls_tab_lock);
	return ret;
}

/**
 * \fn extls_register_dyn_tls_segment
 * \brief Iterate through program header to detect (after init) new loaded TLS modules
 *
 * This routine is exclusively called by extls_dlopen().
 * \see extls_dlopen()
 *
 * \param filename object file previously loaded
 * \param handler dlopen()-generated handler to this object file
 * \return
 * <ul>
 * <li><b>EXTLS_NOMEM</b> if unable to allocate (first time) the global table</li>
 * <li><b>EXTLS_SUCCESS</b> otherwise</li>
 * </ul>
 */
extls_ret_t extls_register_dyn_tls_segment(const char* filename, void * handler)
{
	extls_ret_t ret = EXTLS_SUCCESS;

	extls_wlock(&tls_tab_lock);
	dyn_data_t data = {filename, handler};

	if(!tls_segs_tab)
	{
		tls_segs_tab = malloc(sizeof(extls_tls_seg_t) * TLS_SEGS_NB_MAX);
		if(!tls_segs_tab) return EXTLS_ENOMEM;
	}

	ret = dl_iterate_phdr(extls_lookfor_tls_segment, (void*)&data);
	extls_wunlock(&tls_tab_lock);

	return ret;
}

/**
 * Pass through all program header to register all not-already-discovered TLS segment and insert them
 * into the global table.
 *
 * \return
 * <ul>
 * <li><b>EXTLS_NOMEM</b> if unable to allocate (first time) the global table</li>
 * <li><b>EXTLS_SUCCESS</b> otherwise</li>
 * </ul>
 */
extls_ret_t extls_register_tls_segments(void)
{
	extls_ret_t ret = EXTLS_SUCCESS;
	extls_wlock(&tls_tab_lock);
	if(!tls_segs_tab)
	{
		tls_segs_tab = malloc(sizeof(extls_tls_seg_t) * TLS_SEGS_NB_MAX);
		if(!tls_segs_tab) return EXTLS_ENOMEM;
	}

	ret = dl_iterate_phdr(extls_lookfor_tls_segment, NULL);
	extls_wunlock(&tls_tab_lock);
	return ret;
}

/**
 * Retrieve the current number of registerd tls segments (global)
 * \return a positive number
 */
extls_size_t extls_get_nb_tls_segments(void)
{
	size_t ret;
	extls_rlock(&tls_tab_lock);
	ret = tls_segs_nb;
	extls_runlock(&tls_tab_lock);
	return ret;
}

/**
 * Retrieve the number of loaded-at-startup TLS segments.
 *
 * This function allows us to know if a given module is a static or dynamic one.
 * Combined to extls_get_nb_tls_segments(), you can find the number of
 * dynamic TLS segments
 *
 * \return a positive number
 */
extls_size_t extls_get_nb_static_tls_segments(void)
{
	assert(offset_table != NULL);
	return offset_table[0];
}

extls_size_t extls_get_sz_static_tls_segments(void)
{
	assert(offset_table != NULL);
	return offset_table_memsz; 
}

/**
 * Retrieve a module offset inside the first static TLS segment from its module value
 *
 * Function used to convert a module id to the absolute offset. Works only for TLS modules
 * loaded at startup.
 *
 * \param module_id the module id to convert
 *
 * \return a positive value.
 */
extls_size_t extls_get_offset_for(extls_size_t module_id)
{
	assert(offset_table != NULL);
	assert(module_id <= offset_table[0]);

	return offset_table[module_id];
}

extls_size_t extls_get_seg_size_for(extls_size_t module_id)
{
	assert(offset_table != NULL);
	assert(module_id <= tls_segs_nb);
	return tls_segs_tab[module_id].seg_memsz;
}

/**
 * create a file which contains all static TLS segments.
 *
 * This allows us to create a contiguous segment (here a file), representing static TLS.
 * This file will then be mapped by each level. The parameter "table" is used for thread-safety,
 * its content cannot be updated in the real global table until the parent function ends.
 *
 * \param table the temporary global table where the offset will be then stored
 *
 * \return
 * <ul>
 * <li><b>EXTLS_EOPEN</b> if unable to open the file (especially if /tmp is not writable)
 * <li><b>EXTLS_EWRITE</b> if unable to write in the file (at any time)</li>
 * <li><b>EXTLS_SUCCESS</b> otherwise</li>
 * </ul>
 */
static extls_ret_t extls_generate_static_segment_file(extls_size_t* table)
{
	int fd = -1;
	char name[1024];
	extls_size_t nb, total_size, page_size, alignment, debug_cnt = 0;

	snprintf(name, 1024, "/tmp/extls_map_static_tls_segmt_%d", getpid());
	fd = open(name, O_CREAT | O_RDWR | O_TRUNC, S_IRWXU);
	if(fd == -1)
	{
		return EXTLS_EOPEN;
	}

	nb = extls_get_nb_tls_segments();
	assert(nb == table[0]); /* sanity check */

	extls_dbg("Context (first) : Generating Static Segment Block File");
	/* Here, we compute how many bytes have to be used to align
	 * TLS blocks with the last address (indexed w/ negative offsets)
	 */
	assert(static_order != NULL);
	total_size = table[static_order->idx];
	page_size  = getpagesize();
	alignment  = page_size - (total_size % page_size);
	offset_table_memsz = total_size + alignment;
	assert(offset_table_memsz % page_size == 0);

	/* set file content (for padding) */
	if(ftruncate(fd, offset_table_memsz) != 0) return EXTLS_EWRITE;
	lseek(fd, alignment, SEEK_SET);
	
	/* used for segment build debugging */
	debug_cnt  = offset_table_memsz;
	debug_cnt -= alignment;

	/* we have to pass through TLS blocks in a reverse order
	 * static TLS blocks have to be indexed like that, TLS optimizations infers
	 * TLS address through a negative offset (in GNU model).
	 * WARNING: Due to potential reordering, we pick the right order from the 
	 * chained list constructed when TLS blocks offset have been computed
	 */
	elem_t* cur = static_order;
	while(cur)
	{
		extls_tls_seg_t seg = tls_segs_tab[cur->idx-1];
		/* write the .tdata section */
		if(write(fd, seg.seg_addr, seg.seg_filesz) < 0) return EXTLS_EWRITE;
		/* complete to add the ".tbss" section: init w/ zeros, assuming filesz < memsz */
		if(extls_write_zeros(fd, seg.seg_memsz - seg.seg_filesz) != EXTLS_SUCCESS) return EXTLS_EWRITE;
		
		/* un-comment these lines to print level building, segment by segment */
		//extls_debug("0x%x -> 0x%x : %s (.tdata)", debug_cnt, debug_cnt - seg.seg_filesz, seg.obj_name);
		//extls_debug("0x%x -> 0x%x : %s (.tbss + align)", debug_cnt - seg.seg_filesz, debug_cnt - seg.seg_memsz, seg.obj_name);
    		debug_cnt -= seg.seg_memsz;

		/* WARNING: current elem are in an incoherent state after that ! */
		SAFE_FREE(cur);
	}

	remove(name);
	/* important to not close the fd => used for mmap() */
	offset_table_fd = fd;

	return EXTLS_SUCCESS;

}

/**
 * fill the global offset table, used to retrieve the module offset in the static TLS block
 *
 * \warning This function should only be executed once per process !
 *
 * \return a pointer refering the local offset table (need thread-safety)
 */
extls_size_t* extls_create_static_segment_offset_table(void)
{
	extls_size_t nb;
	extls_size_t idx, offset = 0, start_last_gap = 0, end_last_gap = 0, gap_owner=0;
	extls_size_t* local_offset_table = NULL;

    extls_dbg("Context (first) : Initializing Static Offset Table");

	/* sometimes, we need to force the lookup */
	if(extls_get_nb_tls_segments() <= 0)
		extls_register_tls_segments();

	nb = extls_get_nb_tls_segments();
	local_offset_table = malloc((nb+1) * sizeof(extls_size_t));

	if(!local_offset_table)
	{
		return NULL;
	}

	local_offset_table[0] = nb;

	//extls_print_tls_segments(); /* uncomment to print current lookup result */

	/* here we consider all static TLS segments have been detected (and only them)
	 * We have to update memsz of each segment to respect alignment.
	 * According to U.Drepper, the template should be as follow:
	 * - First Blocks (exe)  = roundup(block size, block alignment)
	 * - Other blocks (libs) = roundup(offset_previous + size_current, align_current).
	 * Here, we update seg_memsz for each segments.
	 * WARNING: If some dynamic segments have been loaded, they will be aligned too
	 * (maybe not what we want).
	 *
	 * From LIBC implementation, when some blocks are aligned, the inserted gap is registered
	 * If one of next blocs can fit in the empty slot, then the loader tries to move the block
	 * in the gap. As we rely on loader-generated offset, we need to do the same when
	 * the static block is created.
	 */
	extls_dbg("Context (first) : Compute Static TLS Block Offset");
	for(idx = 1; idx <= nb; idx++)
	{
		extls_tls_seg_t* seg = &tls_segs_tab[idx-1];

		/* if the current segment can be inserted in the "last seen" slot created because of alignment */
		if((end_last_gap - start_last_gap) >= seg->seg_memsz)
		{
			/* To be sure the block can fit, we compute its real size: with its alignment requirement */
			extls_size_t aligned_memsz = roundup(start_last_gap + seg->seg_memsz, seg->seg_align);

			/* If the block can still fit in the gap -> do it */
			if(end_last_gap >= aligned_memsz)
			{
				/* remember the aligned segment size */
				extls_size_t sz_with_padding = aligned_memsz - start_last_gap;
				start_last_gap = aligned_memsz;

				/* We try to find which block created the padding */
				if(gap_owner > 0)
				{
					/* it is not its job to copy the padding, its the current segment responsibility */
					tls_segs_tab[gap_owner-1].seg_memsz -= sz_with_padding;
				}
        
				/* Insert the current block after the one which created the slot (write from last to first) */
				INSERT_AFTER_EQUAL(static_order, idx, gap_owner);

				/* update the current memsz to handle the potential inserted padding */
				seg->seg_memsz = sz_with_padding;
				local_offset_table[idx] = aligned_memsz;
				continue;
			}
		}
	
		/* 
		 * Here, we suppose the current block cannot be inserted in the last known gap.
		 * If the block is inserted without alignment (no padding), the last gap remains the one registered
		 */
		extls_size_t aligned_block = roundup(offset + seg->seg_memsz, seg->seg_align);
		extls_size_t padding       = aligned_block - (offset + seg->seg_memsz);
		
		/* the current block will need some padding to be inserted
		 * If the newly created gap is larger than the registered one, we keep the new one.
		 * The idea here is to have the same behavior as the libc,
		 * where the first encountered and largest block is filled.
		 *
		 * The major drawback of the this libc's implementation is that we lose any 
		 * "intermediate" padding space created by non-reorderable TLS blocks.
		 */
		if(aligned_block > offset + seg->seg_memsz + (end_last_gap - start_last_gap))
		{
			start_last_gap = offset;
			end_last_gap   = aligned_block - seg->seg_memsz;
			gap_owner = idx;
		}
		
		/* increase the size to include the padding, in any case.
		 * This could be substracted if the padding is used later (\see extls_generate_static_segment_file())*/
		seg->seg_memsz += padding;


		/* set the current block as the first to be written, for now */
		PREPEND_TO(static_order, idx);

		offset = aligned_block;
		
		local_offset_table[idx] = offset;
		//extls_debug("%s: 0x%x (pad: 0x%x)", seg->obj_name, offset, padding); /* uncomment to print each reordered segment */
	}

	/* we generate the associated file, ready to be dumped */
	if(extls_generate_static_segment_file(local_offset_table) != EXTLS_SUCCESS)
	{
		free(local_offset_table);
		local_offset_table = NULL;
	}
	return local_offset_table;
}

/**
 * create the map of static TLS segment for a given context and a given TLS level
 *
 * \param level the level for whom the map is targeted
 *
 * \return
 * <ul>
 * <li><b>EXTLS_ENOMEM</b> if the map failed</li>
 * <li><b>EXTLS_SUCCESS</b> otherwise</li>
 * </ul>
 */
extls_ret_t extls_map_static_segment(extls_object_level_t* level)
{
	extls_ret_t ret = EXTLS_SUCCESS;
	level->static_seg = NULL;

	if(offset_table == NULL)
	{
		extls_lock(&offset_table_lock);
		/* double "if" to reduce contention after the init ! */
		if(offset_table == NULL)
		{
			/* we have to get the pointer from a local-created one !
			 * If not, the first "if" will be true before the array is completely initialized
			 */
			offset_table = extls_create_static_segment_offset_table();
			if(offset_table == NULL)
			{
				extls_fatal("Unable to create the initial static block file !");
			}
		}
		extls_unlock(&offset_table_lock);
	}

	/* the offset_table_memsz is set by extls_create_static_segment_offset_table() (called just above) */
	level->static_seg = mmap(NULL,offset_table_memsz, PROT_READ | PROT_WRITE, MAP_PRIVATE, offset_table_fd, 0);
	if(level->static_seg == MAP_FAILED)
	{
		ret = EXTLS_ENOMEM;
	}

	extls_dbg("Context: Create projection ["GRE"%p"BLU" -> "RED"%p"BLU"]",
		level->static_seg,
		(char*)(level->static_seg) + offset_table_memsz);

	level->static_seg += offset_table_memsz;
	return ret;
}

/**
 * compute the TLS offset for a dynamically loaded library.
 *
 * Caught by dlsym(), we have the symbol name and want to find the offset of the symbol inside
 * the object. We use a system call to compute that (not very clean, but it works).
 * Obviously, we have to check if the symbol is a TLS. If not, the real dlsym() should be called
 * for looking up.
 *
 * \param idx the index in global table depicting the targeted dynamic object
 * \param sym the symbol name
 * \param off_out we write the effective offset (if valid) in it
 *
 * \return
 * <ul>
 * <li><b>EXTLS_ENFOUND</b>If the symbol is not a TLS able to handled by us. off_out state is undefined</li>
 * <li><b>EXTLS_SUCCESS</b>otherwise</li>
 * </ul>
 */
extls_ret_t extls_get_dyn_tls_offset(extls_size_t idx, const char * sym, extls_size_t* off_out)
{
	const short SIZE = 1024;
	char command[SIZE];
	char result[SIZE];
	extls_size_t nb = 0;

	/* generate the command to run to find the TLS offset (if exist) */
	snprintf(command, SIZE, "(readelf -s %s | grep TLS | grep \"%s\" | tr -s \" \" | cut -d' ' -f3 | sort | uniq) 2>&1", tls_segs_tab[idx].obj_name, sym);

	FILE* fd  = popen(command, "r");
	assert(fd != NULL);
	nb = fread(result, sizeof(char), SIZE, fd);
	/* if the command does not produce a value, it is not a TLS (or we don't handle it) */
	if(nb == 0)
	{
		return EXTLS_ENFOUND;
	}

	/* convert a string into size_t and keep a hexadecimal format */
	*off_out = strtoull(result, NULL, 16 );
	pclose(fd);
	return EXTLS_SUCCESS;
}

/**
 * create the map for a dynamic TLS segment
 *
 * To avoid consume too much memory, dynamic segment are malloc'd instead of being mmap'd
 * This function is protected through locks because of sharing TLS levels among multiple threads
 * is possible
 *
 * \param tls_level the TLS level for whose the dynamic segment is initialized
 * \param dyn_module The corresponding offset in global lookup table where initial TLS block is stored
 *
 * \return
 * <ul>
 * <li><b>EXTLS_ENOMEM</b> if the dynamic copy cannot be malloc'd</li>
 * <li><b>EXTLS_SUCCESS</b> otherwise</li>
 * </ul>
 */
extls_ret_t extls_map_dynamic_segment(extls_object_level_t* tls_level, extls_size_t dyn_module)
{
	int fd = -1;
	extls_ret_t ret = EXTLS_SUCCESS;
	/* shared level lock. A first check can be done by thread to ensure the the segment is not mapped */
	extls_lock(tls_level->dyn_lock);
	if(tls_level->dyn_seg[dyn_module] == UNALLOCATED_MODULE)
	{
		/* allocate the dynamic segment if not already */
		extls_tls_seg_t seg = tls_segs_tab[dyn_module + offset_table[0]];
		extls_object_t temp_alloc = NULL;
		if(seg.seg_memsz >= (extls_size_t)getpagesize())
		{
			char filename[1024];
			snprintf(filename, 1024, "/tmp/extls_map_%lu_dynamic_tls_segmt_%p_%d", dyn_module, tls_level, getpid());
			fd = open(filename, O_CREAT | O_RDWR | O_TRUNC, S_IRWXU);
			if(fd == -1)
			{
				ret = EXTLS_EOPEN;
				goto ret_func;
			}

			if(write(fd, seg.seg_addr, seg.seg_filesz) < 0)
			{
				ret = EXTLS_EWRITE;
				goto ret_func;
			}

			temp_alloc = mmap(NULL,seg.seg_memsz, PROT_READ | PROT_WRITE, MAP_PRIVATE, fd, 0);
			if(temp_alloc == MAP_FAILED)
			{
				ret = EXTLS_ENOMEM;
				goto ret_func;
			}

			/* no need to set to 0 (done by mmap() call) */
			memcpy(temp_alloc, seg.seg_addr, seg.seg_filesz);

			close(fd);
			remove(filename);
		}
		else
		{
			/* init the segment w/ data:
			 * - mempcpy() inits the segment w/ .tdata and returns the first byte addressable AFTER the copy.
			 * - memset() inits then the segment w/ zeros (eq. .tbsss)
			 */
			temp_alloc = malloc(seg.seg_memsz);
			if(!temp_alloc)
			{
				ret = EXTLS_ENOMEM;
				goto ret_func;
			}
			memset(
				mempcpy(temp_alloc, seg.seg_addr, seg.seg_filesz), /* copy the .tdata */
				0, /* reset the .tbss equivalent w/ memset of '0' byte */
				seg.seg_memsz - seg.seg_filesz);
		}

		/* increment the number of allocated segment */
		(*tls_level->nb_dyn_seg)++;

		tls_level->dyn_seg[dyn_module] = temp_alloc;
	}

ret_func:
	extls_unlock(tls_level->dyn_lock);
	return ret;
}

